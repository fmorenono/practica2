---
title: 'PRACTICA 2.'
author: "Victor Manuel Vásquez Rivas - Francisco Javier Moreno Hernández"
date: "Mayo 2019"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
      in_header: input/header.html
  pdf_document:
    highlight: zenburn
    toc: yes
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval=T, echo=T)
```

******
# Descripción, limpieza y tratamiento en los datos
******

## Descripción del dataset. ¿Por qué es importante y qué pregunta/problema pretende responder? 

El data set que hemos seleccionado, llamado "heart-disease-uci", o lo que es lo mismo, "enfermedades-corazon-uci", se refiere a pacientes.  Tenemos una lista de atributos con características de los pacientes, como son edad, sexo, colesterol en sangre, máximo ritmo cardíaco y otros indicadores médicos. La variable "target" indica si el paciente tiene enfermedad cardíaca o no y es la variable sobre la que querremos hacer predicciones.

Hemos encontrado el data set interesante porque aunque los datos en el csv son numéricos ya vemos de un principio que hay datos categóricos. 

Por otra parte, la variable "target" parece que nos va a permitir realizar estudios de diferente tipo como son: clasificación de pacientes, regresiones para predecir el valor, etc.

```{r}

diseases<-read.csv("input/heart.csv", sep=",",na.strings = "NA")
dim(diseases)
str(diseases)
summary(diseases)

```

## Integración y selección de los datos de interés a analizar. 

A continuación se describirán el significado de cada una de las variables del data set:
<ul>
<li>age: edad en años.</li>
<li>sex: 1 = masculino; 0 = femenino.</li>
<li>cp: tipo de dolor de pecho.</li>
<li>trestbps: presión arterial en reposo (en mm Hg al ingreso en el hospital).</li>
<li>chol: suero colestoral en mg/dl.</li>
<li>fbs: azúcar en la sangre en ayunas > 120 mg/dl (1 = verdadero; 0 = falso).</li>
<li>restecg: resultados de electrocardiograma en reposo.</li>
<li>thalach: maximo ritmo cardiaco alcanzado</li>
<li>exang: angina inducida por el ejercicio (1 = sí; 0 = no)</li>
<li>oldpeak: depresión del ST inducida por el ejercicio en relación con el descanso.</li>
<li>slope: Pendiente maxima del segmento del ejercicio ST.</li>
<li>ca: número de vasos principales (0-3) coloreados por fluoroscopia.</li>
<li>thal: 3 = normal; 6 = defecto fijo; 7 = defecto reversible</li>
<li>target: 1 o 0</li>
</ul>


Para la selección de los atributos, comenzaremos revisando las relaciones entre los distintos atributos y el atributo target el cual indica si existe o no un problema cardiaco, así diagnosticar si son representativos o pueden ser eliminados.


```{r}
#Cargamos antes algunas librerías que utilizaremos
if(!require(ggplot2)){
    install.packages('ggplot2', repos='http://cran.us.r-project.org')
    library(ggplot2)
}
if(!require(grid)){
    install.packages('grid', repos='http://cran.us.r-project.org')
    library(grid)
}
if(!require(gridExtra)){
    install.packages('gridExtra', repos='http://cran.us.r-project.org')
    library(gridExtra)
}
if(!require(fBasics)){
    install.packages('fBasics', repos='http://cran.us.r-project.org')
    library(fBasics)
}

#Trasformaremos algunos datos para poder grafcar las variables y encontrar las de interés

diseases$target.tipo[diseases$target == 0 ]="Sin Problemas Cardiacos"
diseases$target.tipo[diseases$target > 0 ]="Con Problemas Cardiacos"
diseases$age.tipo[diseases$age < 40 ]="Menores a 40"
diseases$age.tipo[diseases$age >= 40 & diseases$age < 50 ]="Mayor a 40 y menor a 50"
diseases$age.tipo[diseases$age >= 50 & diseases$age < 60 ]="Mayor a 50 y menor a 60"
diseases$age.tipo[diseases$age >= 60 & diseases$age < 70 ]="Mayor a 60 y menor a 70"
diseases$age.tipo[diseases$age >= 70 ]="Mayores a 70"
diseases$sex.tipo[diseases$sex == 0 ] = "Femenino"
diseases$sex.tipo[diseases$sex == 1 ] = "Masculino"
diseases$cp.tipo = as.factor(diseases$cp)
diseases$trestbps.tipo[diseases$trestbps < 100] = "Menor a 100"
diseases$trestbps.tipo[diseases$trestbps >= 100 & diseases$trestbps < 140] = "Mayor a 100 y menor a 150"
diseases$trestbps.tipo[diseases$trestbps >= 140 & diseases$trestbps < 180] = "Mayor a 140 y menor a 180"
diseases$trestbps.tipo[diseases$trestbps >= 180] = "Mayor a 180"
diseases$chol.tipo[diseases$chol < 200] = "Menor a 200"
diseases$chol.tipo[diseases$chol >= 200 & diseases$chol < 300] = "Mayor a 200 y menor a 300"
diseases$chol.tipo[diseases$chol >= 300 & diseases$chol < 400] = "Mayor a 300 y menor a 400"
diseases$chol.tipo[diseases$chol >= 400] = "Mayor a 400"
diseases$fbs.tipo = as.factor(diseases$fbs)
diseases$restecg.tipo = as.factor(diseases$restecg)
diseases$thalach.tipo[diseases$thalach < 100] = "Menor a 100"
diseases$thalach.tipo[diseases$thalach >= 100 & diseases$thalach  < 150] = "Mayor a 100 y menor a 150"
diseases$thalach.tipo[diseases$thalach >= 150 & diseases$thalach  < 200] = "Mayor a 150 y menor a 200"
diseases$thalach.tipo[diseases$thalach >= 200] = "Mayor a 100"
diseases$exang.tipo = as.factor(diseases$exang)
diseases$oldpeak.tipo[diseases$oldpeak < 1] = "Menor a 1"
diseases$oldpeak.tipo[diseases$oldpeak >= 1 & diseases$oldpeak < 2] = "Mayor a 1 y menor a 2"
diseases$oldpeak.tipo[diseases$oldpeak >= 2 & diseases$oldpeak < 3] = "Mayor a 2 y menor a 3"
diseases$oldpeak.tipo[diseases$oldpeak >= 3 & diseases$oldpeak < 4] = "Mayor a 3 y menor a 4"
diseases$oldpeak.tipo[diseases$oldpeak >= 4 & diseases$oldpeak < 5] = "Mayor a 4 y menor a 5"
diseases$oldpeak.tipo[diseases$oldpeak >= 5] = "Mayor a 5"
diseases$slope.tipo = as.factor(diseases$slope)
diseases$ca.tipo = as.factor(diseases$ca)
diseases$thal.tipo = as.factor(diseases$thal)


# Distribución de las edades
ggplot(diseases,aes(x = age)) + geom_density(bins =30,fill ="#52BE80") + theme_bw() + theme_classic() +ggtitle("Distribución de las edades") +ylab("Cantidad de personas")

# Distribución de problemas cardiacos por edad
ggplot(diseases,aes(age.tipo,fill=target.tipo))+geom_bar() +labs(x="Tipo Edad", y="Problemas cardiacos")+ guides(fill=guide_legend(title=""))+ ggtitle("Problemas cardiacos por edades")+ scale_fill_manual(values=c("#52BE80","#F4D03F")) + theme(axis.text.x = element_text(angle = 30, hjust = 1))

# Distribución por sexo
ggplot(diseases,aes(x =sex.tipo)) + geom_bar(width = 0.2,fill ="#52BE80") + geom_text(stat = 'count',aes(label =..count..),vjust =-0.5) + theme_bw() + theme_classic() +ylab("Cantidad") + ggtitle("sex") 

# Distribución de problemas cardiacos por sexo
ggplot(diseases,aes(sex.tipo,fill=target.tipo))+geom_bar() +labs(x="Tipo sexo", y="Problemas cardiacos")+ guides(fill=guide_legend(title=""))+ ggtitle("Problemas cardiacos por sexo")+ scale_fill_manual(values=c("#52BE80","#F4D03F")) + theme(axis.text.x = element_text(angle = 30, hjust = 1))

# Distribución por CP
ggplot(diseases,aes(x =cp.tipo)) + geom_bar(width = 0.2,fill ="#52BE80") + geom_text(stat = 'count',aes(label =..count..),vjust =-0.5) + theme_bw() + theme_classic() +ylab("Cantidad") + ggtitle("CP") 

# Distribución de problemas cardiacos por CP
#Esta es una variable importante en donde podemos ver que si el tipo de CP es 0 existen menos probabilidades que tenga un problema cardiaco.
ggplot(diseases,aes(cp.tipo,fill=target.tipo))+geom_bar() +labs(x="Tipo cp", y="Problemas cardiacos")+ guides(fill=guide_legend(title=""))+ ggtitle("Problemas cardiacos por cp")+ scale_fill_manual(values=c("#52BE80","#F4D03F"))


# Distribución por trestbps
ggplot(diseases,aes(x = trestbps)) + geom_density(bins =30,fill ="#52BE80") + theme_bw() + theme_classic() +ggtitle("Distribución atributo trestbps")  + ylab("Cantidad")

# Distribución de problemas cardiacos por trestbps
ggplot(diseases,aes(trestbps.tipo,fill=target.tipo))+geom_bar() +labs(x="Tipo trestbps", y="Problemas cardiacos")+ guides(fill=guide_legend(title=""))+ ggtitle("Problemas cardiacos por trestbps")+ scale_fill_manual(values=c("#52BE80","#F4D03F")) + theme(axis.text.x = element_text(angle = 30, hjust = 1))


# Distribución chol
ggplot(diseases,aes(x = chol)) + geom_density(bins =30,fill ="#52BE80") + theme_bw() + theme_classic() +ggtitle("Distribución atributo chol")  + ylab("Cantidad")

# Distribución de problemas cardiacos por Chol
ggplot(diseases,aes(chol.tipo,fill=target.tipo))+geom_bar() +labs(x="Tipo chol", y="Problemas cardiacos")+ guides(fill=guide_legend(title=""))+ ggtitle("Problemas cardiacos por chol")+ scale_fill_manual(values=c("#52BE80","#F4D03F")) + theme(axis.text.x = element_text(angle = 30, hjust = 1))

# Distribución fbs
ggplot(diseases,aes(x =fbs.tipo)) + geom_bar(width = 0.2,fill ="#52BE80") + geom_text(stat = 'count',aes(label =..count..),vjust =-0.5) + theme_bw() + theme_classic() +ylab("Cantidad") + ggtitle("fbs") 

# Distribución de problemas cardiacos por fbs
ggplot(diseases,aes(fbs.tipo,fill=target.tipo))+geom_bar() +labs(x="Tipo fbs", y="Problemas cardiacos")+ guides(fill=guide_legend(title=""))+ ggtitle("Problemas cardiacos por fbs")+ scale_fill_manual(values=c("#52BE80","#F4D03F")) 


# Distribución restecg
ggplot(diseases,aes(x =restecg.tipo)) + geom_bar(width = 0.2,fill ="#52BE80") + geom_text(stat = 'count',aes(label =..count..),vjust =-0.5) + theme_bw() + theme_classic() +ylab("Cantidad") + ggtitle("restecg") 

# Distribución de problemas cardiacos por restecg
ggplot(diseases,aes(restecg.tipo,fill=target.tipo))+geom_bar() +labs(x="Tipo restecg", y="Problemas cardiacos")+ guides(fill=guide_legend(title=""))+ ggtitle("Problemas cardiacos por restecg")+ scale_fill_manual(values=c("#52BE80","#F4D03F")) 


# Distribución thalach
ggplot(diseases,aes(x = thalach)) + geom_density(bins =30,fill ="#52BE80") + theme_bw() + theme_classic() +ggtitle("Distribución atributo thalach")  + ylab("Cantidad")

# Distribución de problemas cardiacos por thalach
ggplot(diseases,aes(thalach.tipo,fill=target.tipo))+geom_bar() +labs(x="Tipo thalach", y="Problemas cardiacos")+ guides(fill=guide_legend(title=""))+ ggtitle("Problemas cardiacos por thalach")+ scale_fill_manual(values=c("#52BE80","#F4D03F")) + theme(axis.text.x = element_text(angle = 30, hjust = 1))


# Distribución exang
ggplot(diseases,aes(x =exang.tipo)) + geom_bar(width = 0.2,fill ="#52BE80") + geom_text(stat = 'count',aes(label =..count..),vjust =-0.5) + theme_bw() + theme_classic() +ylab("Cantidad") + ggtitle("exang") 

# Distribución de problemas cardiacos por exang
ggplot(diseases,aes(exang.tipo,fill=target.tipo))+geom_bar() +labs(x="Tipo exang", y="Problemas cardiacos")+ guides(fill=guide_legend(title=""))+ ggtitle("Problemas cardiacos por exang")+ scale_fill_manual(values=c("#52BE80","#F4D03F"))


# Distribución oldpeak
ggplot(diseases,aes(x = oldpeak)) + geom_density(bins =30,fill ="#52BE80") + theme_bw() + theme_classic() +ggtitle("Distribución atributo oldpeak")  + ylab("Cantidad")

# Distribución de problemas cardiacos por oldpeak
ggplot(diseases,aes(oldpeak.tipo,fill=target.tipo))+geom_bar() +labs(x="Tipo oldpeak", y="Problemas cardiacos")+ guides(fill=guide_legend(title=""))+ ggtitle("Problemas cardiacos por oldpeak")+ scale_fill_manual(values=c("#52BE80","#F4D03F")) + theme(axis.text.x = element_text(angle = 30, hjust = 1))

# Distribución slope
ggplot(diseases,aes(x =slope.tipo)) + geom_bar(width = 0.2,fill ="#52BE80") + geom_text(stat = 'count',aes(label =..count..),vjust =-0.5) + theme_bw() + theme_classic() +ylab("Cantidad") + ggtitle("slope") 

# Distribución de problemas cardiacos por slope
ggplot(diseases,aes(slope.tipo,fill=target.tipo))+geom_bar() +labs(x="Tipo slope", y="Problemas cardiacos")+ guides(fill=guide_legend(title=""))+ ggtitle("Problemas cardiacos por slope")+ scale_fill_manual(values=c("#52BE80","#F4D03F"))

# Distribución ca
ggplot(diseases,aes(x =ca.tipo)) + geom_bar(width = 0.2,fill ="#52BE80") + geom_text(stat = 'count',aes(label =..count..),vjust =-0.5) + theme_bw() + theme_classic() +ylab("Cantidad") + ggtitle("ca") 

# Distribución de problemas cardiacos por ca
# Podemos observar que con valores en cero mayor es la probabilidad de tener problemas cardiacos
ggplot(diseases,aes(ca.tipo,fill=target.tipo))+geom_bar() +labs(x="Tipo ca", y="Problemas cardiacos")+ guides(fill=guide_legend(title=""))+ ggtitle("Problemas cardiacos por ca")+ scale_fill_manual(values=c("#52BE80","#F4D03F"))


# Distribución thal
ggplot(diseases,aes(x =thal.tipo)) + geom_bar(width = 0.2,fill ="#52BE80") + geom_text(stat = 'count',aes(label =..count..),vjust =-0.5) + theme_bw() + theme_classic() +ylab("Cantidad") + ggtitle("thal") 

# Distribución de problemas cardiacos por thal
ggplot(diseases,aes(thal.tipo,fill=target.tipo))+geom_bar() +labs(x="Tipo thal", y="Problemas cardiacos")+ guides(fill=guide_legend(title=""))+ ggtitle("Problemas cardiacos por thal")+ scale_fill_manual(values=c("#52BE80","#F4D03F"))
```

La variable "thal" presenta inconcistencia en su definición versua los datos descritos anteriormente, por lo que no se utilizará en el modelo.
```{r}
diseases$thal = NULL
diseases$thal.tipo = NULL
```

Como podemos observar, el resto de las variables pueden tener relación en el diagnostico de un problema cardiaco y pueden ser combinadas entre ellas en modelos predictivo.


## Limpieza de los datos. 
### ¿Los datos contienen ceros o elementos vacíos? ¿Cómo gestionarías cada uno de estos casos? 

Primero revisaremos si existen valores NA en el data set, si existiesen les realizaremos el tratamiento correspondiente.

```{r}
# Con la sentencia complete.cases revisamos que cada fila este completa devolviendo TRUE, si alguna fila tuviese NA devolvería FALSE. Guardaremos los valores en un vector para luego revisarlo.
vectorNA <-complete.cases(diseases)
# Revisamos si existe alguna fila con algún valor en NA
vectorNA[FALSE]
```

```{r}
# Otra forma de revisar la existencia de NA es la siguiente.
sapply(diseases, function(x) sum(is.na(x)))
```

Como podemos ver, no existe ninguna fila con valores vacios. Si hubiesen existido podriamos gestionarlos, dependiendo el caso, eliminando el registro o ingresando alguna media de tendencia central.

```{r}
# Si hubiesemos necesitado eliminar los registros que alguna columna tuviese NA, sería con la siguiente instrucción
diseases <- na.omit(diseases)
```

```{r}
# Si alguna columna tuviese NA y su distribución de datos fuese uniforme, utilizariamos la media para reemplazar el datos faltante.
# Por ejemplo, veremos el caso para la columna trestbps (datos de la presión arterial del paciente en reposo), en donde, con la siguiente instrucción reemplazaríamos los NA con la media 
mean(diseases$age[!is.na(diseases$age)])
diseases$age[is.na(diseases$age)] <-  mean(diseases$age[!is.na(diseases$age)])
```


```{r}
# Si alguna columna tuviese NA y su distribución de datos estuviese sesgada, utilizariamos la mediana para reemplazar el datos faltante.
# Por ejemplo, veremos el caso para la columna trestbps (datos de la presión arterial del paciente en reposo), en donde, con la siguiente instrucción reemplazaríamos los NA con la mediana 
median(diseases$trestbps[!is.na(diseases$trestbps)])
diseases$trestbps[is.na(diseases$trestbps)] <-  median(diseases$trestbps[!is.na(diseases$trestbps)])
```

Como podemos observar en el punto 2, al momento de analizar los datos de interés, se mostró la distribución de cada una de las columnas, en donde se logra validar que no existe valores en cero los cuales no aporten la realidad del dato. Por ejemplo, para la variable sex, el valor en cero tiene el significado para las personas de sexo femenino, en cambio si hubiese existido para la variable thalach (maximo ritmo cardiaco alcanzado) algún registro con valor en cero, no hubiese tenido sentido ese valor, el cual hubiesemos tenido que reemplazarlos por algún valor a convenir. Muchas veces tiene más sentido cambiar ese valor cero en NA, ya que en cero nos puede arruinar alguna medida como puede ser la media, en cambio con NA no la podemos considerar para el cálculo de la media.

```{r}
# Para transformar los valores cero en NA, utilizamos la siguiente instrucción
diseases$thalach[diseases$thalach == 0] <- NA
```

Después de transformarla en NA, podemos reemplazarla por alguna medida de tendencia central con alguna técnica descrita anteriormente.

### Identificación y tratamiento de valores extremos. 

A continuación identificaremos los valores extremos (outliers) de aquellas variables que sus datos puedan ser atípicos en relación con el resto.


```{r}
# Variable AGE, no se visualiza valores extremos
boxplot(diseases$age, main = "Distribución variable AGE", ylab = "Cantidad", col ="#bed4de", border = "brown")
boxplot.stats(diseases$age)$out #Muestra los valores extremos si hubiesen 
```

```{r}
# Variable CP, no se visualiza valores extremos
boxplot(diseases$cp, main = "Distribución variable CP", ylab = "Cantidad", col ="#bed4de", border = "brown")
boxplot.stats(diseases$cp)$out #Muestra los valores extremos si hubiesen 
```

```{r}
# Variable trestbps. Podemos ver que existen valores extremos.
boxplot(diseases$trestbps, main = "Distribución variable Trestbps", ylab = "Cantidad", col ="#bed4de", border = "brown")
# Aquí podemos ver valores que salen de lo común, a continuación los imprimiremos aquellos valores
boxplot.stats(diseases$trestbps)$out #Muestra los valores extremos si hubiesen 
```

```{r}
# Variable chol. Podemos ver que existen valores extremos.
boxplot(diseases$chol, main = "Distribución variable Chol", ylab = "Cantidad", col ="#bed4de", border = "brown")
# Imprimimos aquellos valores atípicos
boxplot.stats(diseases$chol)$out #Muestra los valores extremos si hubiesen 
```

```{r}
# Variable restecg, no se visualiza valores extremos
boxplot(diseases$restecg, main = "Distribución variable Restecg", ylab = "Cantidad", col ="#bed4de", border = "brown")
boxplot.stats(diseases$restecg)$out #Muestra los valores extremos si hubiesen 
```

```{r}
# Variable thalach. Podemos ver que existen valores extremos.
boxplot(diseases$thalach, main = "Distribución variable Thalach", ylab = "Cantidad", col ="#bed4de", border = "brown")
# Imprimimos aquellos valores atípicos
boxplot.stats(diseases$thalach)$out #Muestra los valores extremos si hubiesen 
```

```{r}
# Variable exang, no se visualiza valores extremos
boxplot(diseases$exang, main = "Distribución variable Exang", ylab = "Cantidad", col ="#bed4de", border = "brown")
boxplot.stats(diseases$exang)$out #Muestra los valores extremos si hubiesen 
```

```{r}
# Variable oldpeak. Podemos ver que existen valores extremos.
boxplot(diseases$oldpeak, main = "Distribución variable Oldpeak", ylab = "Cantidad", col ="#bed4de", border = "brown")
# Imprimimos aquellos valores atípicos
boxplot.stats(diseases$oldpeak)$out #Muestra los valores extremos si hubiesen 
```

```{r}
# Variable slope, no se visualiza valores extremos
boxplot(diseases$slope, main = "Distribución variable Slope", ylab = "Cantidad", col ="#bed4de", border = "brown")
boxplot.stats(diseases$slope)$out #Muestra los valores extremos si hubiesen 
```

```{r}
# Variable ca. Podemos ver que existen valores extremos.
boxplot(diseases$ca, main = "Distribución variable CA", ylab = "Cantidad", col ="#bed4de", border = "brown")
# Imprimimos aquellos valores atípicos
boxplot.stats(diseases$ca)$out #Muestra los valores extremos si hubiesen 
```


Las variables con valores extremos son trestbps, chol, thalach, oldpeak, ca. Estos serán analizados a continuación para ver que realizar con ellos.
<ul>
<li>trestbps: Esta variable indica la presión arterial en reposo. Los valores extremos que arroja va desde 172 a 200,   con un total de 9 registros. Se revisó la distribución que se describe en el punto 2 y no representan anomalías, ya que se pueden dar estos casos.</li>
<li>chol: Esta variable indica niveles de colesterol. Los valores que arroja va desde 394 a 564, con un total de 5 registros. Estos valores se escapan considerablemente con el resto de los demás datos. Se eliminarán.</li>
<li>thalach: Esta variable indica máximos niveles de ritmo cardiaco alcanzado. El valor extremo arrojado es 71, en donde aparece solo una vez en el data set. Este valor es por bajo lo normal, pero dentro de lo esperado para validar si un paciente presenta problemas cardiacos, por lo que no se eliminará.</li>
<li>oldpeak: Representa la depresión del degmento ST. Los valores que arroja va desde 4.2 a 6.2, con un total de 5 registros. Al revisar estos valores en la distribución de los datos que fueron representados en el punto 2, se escapan del resto de los demás datos, además estos datos extremos se encuentran sesgados en la representación de aquellos pacientes sin problemas cardiacos. Se eliminarán del data set.</li>
<li>ca: Representa el número de vasos principales coloreados por fluoroscopia. Estos valores extremos que encontramos no representa alteraciones en la realidad o valores que nos vaya a distorcionar nuestros modelos predictivos, por lo que no se eliminarán.</li>
</ul>

```{r}
#Eliminamos los valores extremos.
diseases = diseases[diseases$oldpeak < min(boxplot.stats(diseases$oldpeak)$out),]
diseases = diseases[diseases$chol < min(boxplot.stats(diseases$chol)$out),]
```

Finalmente quedamos con 293 registros de 303 iniciales.


### Correlación entre variables

Revisaremos la correlación entre todas las variables númericas, en donde buscaremos correlaciones menores a -0.5 o mayores a 0.5, siendo 1 y -1 correlaciones perfectas y 0 ninguna correlación, de esta manera consideraremos si es suficiente para una posible eliminación de la variable, por considerarla redundante entre ellas.

```{r}
cor(diseases$age, diseases$sex) # correlación entre age y sex
cor(diseases$age, diseases$cp) # correlación entre age y cp
cor(diseases$age, diseases$trestbps) # correlación entre age y trestbps
cor(diseases$age, diseases$chol) # correlación entre age y chol
cor(diseases$age, diseases$fbs) # correlación entre age y fbs
cor(diseases$age, diseases$restecg) # correlación entre age y restecg
cor(diseases$age, diseases$thalach) # correlación entre age y thalach
cor(diseases$age, diseases$exang) # correlación entre age y exang
cor(diseases$age, diseases$oldpeak) # correlación entre age y oldpeak
cor(diseases$age, diseases$slope) # correlación entre age y slope
cor(diseases$age, diseases$ca) # correlación entre age y ca

cor(diseases$sex, diseases$cp) # correlación entre sex y cp
cor(diseases$sex, diseases$trestbps) # correlación entre sex y trestbps
cor(diseases$sex, diseases$chol) # correlación entre sex y chol
cor(diseases$sex, diseases$fbs) # correlación entre sex y fbs
cor(diseases$sex, diseases$restecg) # correlación entre sex y restecg
cor(diseases$sex, diseases$thalach) # correlación entre sex y thalach
cor(diseases$sex, diseases$exang) # correlación entre sex y exang
cor(diseases$sex, diseases$oldpeak) # correlación entre sex y oldpeak
cor(diseases$sex, diseases$slope) # correlación entre sex y slope
cor(diseases$sex, diseases$ca) # correlación entre sex y ca

cor(diseases$cp, diseases$trestbps) # correlación entre cp y trestbps
cor(diseases$cp, diseases$chol) # correlación entre cp y chol
cor(diseases$cp, diseases$fbs) # correlación entre cp y fbs
cor(diseases$cp, diseases$restecg) # correlación entre cp y restecg
cor(diseases$cp, diseases$thalach) # correlación entre cp y thalach
cor(diseases$cp, diseases$exang) # correlación entre cp y exang
cor(diseases$cp, diseases$oldpeak) # correlación entre cp y oldpeak
cor(diseases$cp, diseases$slope) # correlación entre cp y slope
cor(diseases$cp, diseases$ca) # correlación entre cp y ca

cor(diseases$trestbps, diseases$chol) # correlación entre trestbps y chol
cor(diseases$trestbps, diseases$fbs) # correlación entre trestbps y fbs
cor(diseases$trestbps, diseases$restecg) # correlación entre trestbps y restecg
cor(diseases$trestbps, diseases$thalach) # correlación entre trestbps y thalach
cor(diseases$trestbps, diseases$exang) # correlación entre trestbps y exang
cor(diseases$trestbps, diseases$oldpeak) # correlación entre trestbps y oldpeak
cor(diseases$trestbps, diseases$slope) # correlación entre trestbps y slope
cor(diseases$trestbps, diseases$ca) # correlación entre trestbps y ca

cor(diseases$chol, diseases$fbs) # correlación entre chol y fbs
cor(diseases$chol, diseases$restecg) # correlación entre chol y restecg
cor(diseases$chol, diseases$thalach) # correlación entre chol y thalach
cor(diseases$chol, diseases$exang) # correlación entre chol y exang
cor(diseases$chol, diseases$oldpeak) # correlación entre chol y oldpeak
cor(diseases$chol, diseases$slope) # correlación entre chol y slope
cor(diseases$chol, diseases$ca) # correlación entre chol y ca

cor(diseases$fbs, diseases$restecg) # correlación entre fbs y restecg
cor(diseases$fbs, diseases$thalach) # correlación entre fbs y thalach
cor(diseases$fbs, diseases$exang) # correlación entre fbs y exang
cor(diseases$fbs, diseases$oldpeak) # correlación entre fbs y oldpeak
cor(diseases$fbs, diseases$slope) # correlación entre fbs y slope
cor(diseases$fbs, diseases$ca) # correlación entre fbs y ca

cor(diseases$restecg, diseases$thalach) # correlación entre restecg y thalach
cor(diseases$restecg, diseases$exang) # correlación entre restecg y exang
cor(diseases$restecg, diseases$oldpeak) # correlación entre restecg y oldpeak
cor(diseases$restecg, diseases$slope) # correlación entre restecg y slope
cor(diseases$restecg, diseases$ca) # correlación entre restecg y ca

cor(diseases$thalach, diseases$exang) # correlación entre thalach y exang
cor(diseases$thalach, diseases$oldpeak) # correlación entre thalach y oldpeak
cor(diseases$thalach, diseases$slope) # correlación entre thalach y slope
cor(diseases$thalach, diseases$ca) # correlación entre thalach y ca

cor(diseases$exang, diseases$oldpeak) # correlación entre exang y oldpeak
cor(diseases$exang, diseases$slope) # correlación entre exang y slope
cor(diseases$exang, diseases$ca) # correlación entre exang y ca

cor(diseases$oldpeak, diseases$slope)  # correlación entre oldpeak y slope
cor(diseases$oldpeak, diseases$ca)  # correlación entre oldpeak y ca

cor(diseases$slope, diseases$ca) # correlación entre slope y ca

```

Como podemos observar, existe una correlación negativa moderada -0.537684, entre las variables oldpeak y slope, ésta no es muy alta pero se realizarán las pruebas cuando generemos los modelos predictivos, considerando las dos y luego solo una de ellas para ver si mejora el porcentaje de predicción.

```{r}
if(!require(PerformanceAnalytics)){
  install.packages('PerformanceAnalytics', repos='http://cran.us.r-project.org')
  library(PerformanceAnalytics)
}
dat1 <- data.frame(diseases$oldpeak, diseases$slope)
chart.Correlation(dat1) # graficamos la correlación 
```


******
# Análisis y pruebas estadísticas
******
## Análisis de los datos. 

### Selección de los grupos de datos que se quieren analizar/comparar (planificación de los análisis a aplicar). 

La selección de datos finalmente quedará en los siguiente:

```{r}
str(diseases)
```

### Comprobación de la normalidad y homogeneidad de la varianza. 

Vamos a probar la normalalidad de los datos mediante el test Shapiro–Wilk. seleccionamos las variables a las que aplica comprobar la normalidad, que son las variables cuantitativas. Visualizamos unos gráficos en columna, que nos ayudará a intuir su distribución.

```{r}

trestbps<-diseases$trestbps
chol<-diseases$chol
thalach<-diseases$thalach
oldpeak<-diseases$oldpeak





hist(trestbps,main = "Histograma variable trestbps",ylab=names("trestbps"),col=heat.colors(8))
hist(chol,main = "Histograma variable chol",ylab=names("chol"),col=heat.colors(8))
hist(thalach,main = "Histograma variable thalach",ylab=names("thalach"),col=heat.colors(8))
hist(oldpeak,main = "Histograma variable oldpeak",ylab=names("oldpeak"),col=heat.colors(8))




#trestbps<-presión arterial en reposo (en mm Hg al ingreso en el hospital)
shapiro.test(trestbps)

#chol<-suero colestoral en mg/dl
shapiro.test(chol)

#thalach<-maximo ritmo cardiaco alcanzado
shapiro.test(thalach)

#oldpeak<-depresión del ST inducida por el ejercicio en relación con el descanso.
shapiro.test(oldpeak)


```
Respecto a todas la variables, exceptuando la variable chol, los valores del pvalue son muy pequeños y podemos determinar que no tienen una distribución normal (se rechaza la hipótesis nula y por lo tanto asumimos que no hay normalidad en los datos). La variable chol si podemos considerar que tiene distribución normal (pvalue=0.1734>0.05). Si vemos el gráfico de esa variable podemos ver esa característica.


A continuación trataremos el análisis de la varianza.
Vamos a realizar un análisis unifactorial, donde la variable dependiente va a ser chol y la variable independiente será el sexo. En otras palabras, determinaremos si el nivel de chol (suero colestoral en mg/d) viene determinado por el sexo. 
Al tener muestras grandes de más de 30 no es necesario que confirmemos que la distribución de cada grupo (hombres/mujeres) es normal.

```{r}
#tapply(diseases$chol, diseases$sex, mean)
#variable chol<-suero colestoral en mg/dl
fligner.test(chol ~ sex, data = diseases)
#Otra forma de realizar la prueba varianceTest(diseases$chol[diseases$sex=='0'], diseases$chol[diseases$sex=='1'], method = "fligner")

```
Al ser p-value mayor al nivel de significación 0.05 podemos concluir que hay diferencias significativas entre las varianzas.

Ahora repetimos la prueba para las variabels trestbps,thalach y oldpeak y siendo la varaible dependiente tambien el sexo.



```{r}


#variable trestbps<-presión arterial en reposo (en mm Hg al ingreso en el hospital)
fligner.test(trestbps ~ sex, data = diseases)
#variable thalach<-maximo ritmo cardiaco alcanzado
fligner.test(thalach ~ sex, data = diseases)
#variable oldpeak<-depresión del ST inducida por el ejercicio en relación con el descanso.
fligner.test(oldpeak ~ sex, data = diseases)
```

Solo para oldpeak obtenemos un resultado diferente, en el que podemos concluir que no hay diferencias signficativas entre las varianzas. Acabamos nuestro estudio de análisis de varianza aquí. Podría ampliarse con el estudio de otras variables o incluso realizando análisis multifactorial si se requiriera profundizar en algun aspecto concreto del estudio.

### Aplicación de pruebas estadísticas para comparar los grupos de datos. En función de los datos y el objetivo del estudio, aplicar pruebas de contraste de hipótesis, correlaciones, regresiones, etc. Aplicar al menos tres métodos de análisis diferentes. 

A continuación se presentarán tres modelos para el análisis de datos, Árbol de Clasificación, Regresión Logística y Naive Bayes.

******
<h2>Árbol de Clasificación</h2>
******

Vamos a aplicar un árbol de de decisión. Para ello pasamos a factor nuestra variable target. Utilizaremos las 12 primeras variables (las no transformada). Separaremos el dataset en datos de training y datos de testing. Una vez creado el modelo veremos su precisión.

```{r}

#Pasamos a factor para crear el arbol
diseases$target.tipo = as.factor(diseases$target.tipo)
y <- diseases[,14] #target tipo 
X <- diseases[,1:12] 
indexes = sample(1:nrow(diseases), size=floor((2/3)*nrow(diseases)))
trainX<-X[indexes,]
trainy<-y[indexes]
testX<-X[-indexes,]
testy<-y[-indexes]
#Primero visualizamos las reglas
modelClasif <- C50::C5.0(trainX, trainy,rules=TRUE )
summary(modelClasif)
modelClasif <- C50::C5.0(trainX, trainy)
plot(modelClasif,gp = gpar(fontsize = 4))
predicted_model <- predict( modelClasif, testX, type="class" )
print(sprintf("La precisión del árbol es: %.4f %%",100*sum(predicted_model == testy) / length(predicted_model)))

testX[,"target"] <- testy
testX[,"PREDICCION"] <-predict( modelClasif, testX, type="class" )

# Mostramos la matriz de confusión con los datos obtenidos en el test
table(testX[,"target"], testX[,"PREDICCION"], dnn=c("Actual","Predicho"))

# Exportamos los datos de la predicción
write.csv(testX, file="output/ArbolClasificacion.csv")

```
Vemos la precisión obtenida. Podríamos utilizar el modelo para realizar predicciones para realizar predicciones.

Por otra parte podemos destacar algunas reglas importante que se visualizan como son:

-el 92% de los individus que cumplen trestbps <= 146 (presión arterial en reposo),oldpeak <= 0.7 (depresión del ST inducida por el ejercicio en relación con el descanso) y ca <= 0 (número de vasos principales  coloreados por fluoroscopia) tienen problemas cardíacos.

-el 89% de los individus con cp <= 0 (con dolor en el pecho),trestbps <= 115 (se refiere a presión arterial) y ca <= 0 (número de vasos principales  coloreados por fluoroscopia) tienen problema cardíacos.


******
<h2>Modelo de regresión logística</h2>
******

```{r}
#Preparamos los datos en un data set de entrenamiento y otro de test
set.seed(99)
dataRL <- diseases[,1:13]
train.index <-sample(1:nrow(dataRL), size=floor((2/3)*nrow(dataRL)))
train.data <- dataRL[train.index,]
test.data <- dataRL[-train.index,]


# Creamos el modelo de regresión logistica basado en target, la cual es nuestra variable a predecir
modeloRL <- glm(target~.,data =train.data,family =binomial)
summary(modeloRL)


# Agregamos a cada columna del nuestros datos de test la probabilidad y predicción
test.data[, "PROB_SUCCESS"] <- predict(modeloRL, newdata = test.data, type="response")
test.data[, "PREDICCION"] <- ifelse(test.data[, "PROB_SUCCESS"]>=0.5, 1, 0) # si las probabilidades supera el 50% indicamos 1, sino 0 (predicción a la variable target)
head(test.data) # mostramos una muestra de la predicción

# Nos indica la precisión del modelo
print(sprintf("La precisión es: %.4f %%",100*mean(test.data$PREDICCION==test.data$target)))

# Mostramos la matriz de confusión con los datos obtenidos en el test
table(test.data[,"target"], test.data[,"PREDICCION"], dnn=c("Actual","Predicho"))


# Exportamos los datos de la predicción
write.csv(test.data, file="output/RegresionLogistica.csv")
```

******
<h2>Algoritmo Naive Bayes</h2>
******

```{r}
# Instalamos la librería necesaria
if(!require(e1071)){
    install.packages('e1071', repos='http://cran.us.r-project.org')
    library(e1071)
}

# Copiamos el data set para utilizarlo en el algoritmo
dataNV <- diseases[,c("age.tipo","cp.tipo","trestbps.tipo","chol.tipo","restecg.tipo","exang.tipo","oldpeak.tipo","slope.tipo","ca.tipo","target")]
dataNV$target <- as.factor(dataNV$target)

# Creamos nuestros datos para el modelo y test
trainNV.index <-sample(1:nrow(dataNV), size=floor((2/3)*nrow(dataNV)))
trainNV.data <- dataNV[trainNV.index,]
testNV.data <- dataNV[-trainNV.index,]

# Ejecutamos el algoritmo
mod <- naiveBayes(target~ ., data = trainNV.data)
summary(mod)

# Guardamos los valores predichos en el data set de test para luego compararlos
testNV.data[, "PREDICCION"] <- predict(mod, testNV.data)

# Vemos una muestra de las predicciones
head(testNV.data)

# Nos indica la precisión del modelo
print(sprintf("La precisión es: %.4f %%",100*mean(testNV.data$PREDICCION==testNV.data$target)))

# Vemos una tabla de confusión y comparamos los datos predecidos con los reales
table(testNV.data$target, testNV.data$PREDICCION, dnn = c("Actual", "Predicha"))


# Exportamos los datos de la predicción
write.csv(testNV.data, file="output/NaiveBayes.csv")
```



******
<h2>Cross Validation para los modelos propuestos</h2>
******

Pasaremos a revisar con K iteraciones la validez de las predicciones de los modelos seleccionados. La cantidad de iteraciones elegidas es 10.

```{r}
library(caret)
folds <- createFolds(dataRL$target, k = 10)

# Cross Validation para Árbol de Clasificación
# Iteramos el método de Árbol de Clasificación en K veces para probar nuestro modelo y predecir su verdadera efectividad
cvC50ArbolClasificacion <- lapply(folds, function(x){
  trainX<-X[-x,]
  trainy<-y[-x]
  testX<-X[x,]
  testy<-y[x]
  modelClasif <- C50::C5.0(trainX, trainy)
  predicted_model <- predict( modelClasif, testX, type="class" )
  precision <- sum(predicted_model == testy) / length(predicted_model)
  return(precision)
})
#Calculamos la media aritmética de k iteraciones
precisionC50ArbolClasificacion <- mean(as.numeric(cvC50ArbolClasificacion))
print(sprintf("La precisión para Árbol de clasificación en Cross Validation: %.4f %%",100*precisionC50ArbolClasificacion))



# Cross Validation para Regresion Logistica
# Iteramos el método Regresion Logistica en K veces para probar nuestro modelo y predecir su verdadera efectividad
cvRegresionLogistica <- lapply(folds, function(x){
  training_fold <- dataRL[-x, ]
  test_fold <- dataRL[x, ]
  clasificador <- glm(target ~ ., family = binomial, data = training_fold)
  y_pred <- predict(clasificador, type = 'response', newdata = test_fold)
  y_pred <- ifelse(y_pred > 0.5, 1, 0)
  #y_pred <- factor(y_pred, levels = c("0", "1"), labels = c("NoPulsar", "Pulsar"))
  cm <- table(test_fold$target, y_pred)
  precision <- (cm[1,1] + cm[2,2]) / (cm[1,1] + cm[2,2] +cm[1,2] + cm[2,1])
  return(precision)
})
#Calculamos la media aritmética de k iteraciones
precisionRegresionLogistica <- mean(as.numeric(cvRegresionLogistica))
print(sprintf("La precisión de Regresión Logística en Cross Validation: %.4f %%",100*precisionRegresionLogistica))


# Cross Validation para NaiveBayes
# Iteramos el método de NaiveBayes en K veces para probar nuestro modelo y predecir su verdadera efectividad
cvNaiveBayes <- lapply(folds, function(x){
  training_fold <- dataNV[-x, ]
  test_fold <- dataNV[x, ]
  clasificador <- naiveBayes(target ~ ., data = training_fold)
  y_pred <- predict(clasificador, newdata = test_fold)
  cm <- table(test_fold$target, y_pred)
  precision <- (cm[1,1] + cm[2,2]) / (cm[1,1] + cm[2,2] +cm[1,2] + cm[2,1])
  return(precision)
})

#Calculamos la media aritmética de k iteraciones
precisionNaiveBayes <- mean(as.numeric(cvNaiveBayes))
print(sprintf("La precisión para NaiveBayes en Cross Validation: %.4f %%",100*precisionNaiveBayes))
```

A continuación se mostrarán los métodos ordenados descendentemente por el porcentaje y error de predicción, la varianza y desviación estandar de todos los modelos que se sometieron al cross validation.

```{r}
vectorMedia = c(precisionC50ArbolClasificacion*100,precisionRegresionLogistica*100,precisionNaiveBayes*100)
vectorError = c(100-precisionC50ArbolClasificacion*100,100-precisionRegresionLogistica*100,100-precisionNaiveBayes*100)
vectorVarianza = c(var(as.numeric(cvC50ArbolClasificacion)*100), var(as.numeric(cvRegresionLogistica)*100), var(as.numeric(cvNaiveBayes)*100))
vectorDesviacion = c(sd(as.numeric(cvC50ArbolClasificacion)*100), sd(as.numeric(cvRegresionLogistica)*100), sd(as.numeric(cvNaiveBayes)*100))
M1 = cbind(c("Árbol Clasificacion", "Regresion Logistica","Naive Bayes"),vectorMedia,vectorError, vectorVarianza,vectorDesviacion)
colnames(M1) <- c("Modelo", "Porcentaje Predicción", "Error", "Varianza", "Desviación")
```

```{r}
# Ordenamos y mostramos los resultados
M1[order(M1[,"Porcentaje Predicción"],decreasing = TRUE), ] 
```


Los resultados del Cross Validation nos puede dar la visión por cuál de los modelos nos podemos inclinar, entregando un mejor resultado en la verisidad de la predicción. Para selección del modelo apropiado, podemos tomar como referencia el porcentaje de predicción +- la desviación estandar.



<h2>Probando la eliminación slope por correlación entre oldspeak</h2>

Ahora veremos eliminado la variable slope, probando si la correlación entre oldspeak es suficiente como para eliminarla por redundancia.

```{r}
X$slope <- NULL

# Cross Validation para Árbol de Clasificación sin variable slope
cvC50ArbolClasificacion <- lapply(folds, function(x){
  trainX<-X[-x,]
  trainy<-y[-x]
  testX<-X[x,]
  testy<-y[x]
  modelClasif <- C50::C5.0(trainX, trainy)
  predicted_model <- predict( modelClasif, testX, type="class" )
  precision <- sum(predicted_model == testy) / length(predicted_model)
  return(precision)
})
#Calculamos la media aritmética de k iteraciones
precisionC50ArbolClasificacion <- mean(as.numeric(cvC50ArbolClasificacion))
print(sprintf("La precisión para Árbol de clasificación en Cross Validation: %.4f %%",100*precisionC50ArbolClasificacion))


dataRL <- diseases[,1:13]
dataRL$slope <- NULL
# Cross Validation para Regresion Logistica  sin variable slope
cvRegresionLogistica <- lapply(folds, function(x){
  training_fold <- dataRL[-x, ]
  test_fold <- dataRL[x, ]
  clasificador <- glm(target ~ ., family = binomial, data = training_fold)
  y_pred <- predict(clasificador, type = 'response', newdata = test_fold)
  y_pred <- ifelse(y_pred > 0.5, 1, 0)
  #y_pred <- factor(y_pred, levels = c("0", "1"), labels = c("NoPulsar", "Pulsar"))
  cm <- table(test_fold$target, y_pred)
  precision <- (cm[1,1] + cm[2,2]) / (cm[1,1] + cm[2,2] +cm[1,2] + cm[2,1])
  return(precision)
})
#Calculamos la media aritmética de k iteraciones
precisionRegresionLogistica <- mean(as.numeric(cvRegresionLogistica))
print(sprintf("La precisión de Regresión Logística en Cross Validation: %.4f %%",100*precisionRegresionLogistica))


dataNV <- diseases[,c("age.tipo","cp.tipo","trestbps.tipo","chol.tipo","restecg.tipo","exang.tipo","oldpeak.tipo","slope.tipo","ca.tipo","target")]
dataNV$target <- as.factor(dataNV$target)
dataNV$slope.tipo<- NULL
# Cross Validation para NaiveBayes  sin variable slope
cvNaiveBayes <- lapply(folds, function(x){
  training_fold <- dataNV[-x, ]
  test_fold <- dataNV[x, ]
  clasificador <- naiveBayes(target ~ ., data = training_fold)
  y_pred <- predict(clasificador, newdata = test_fold)
  cm <- table(test_fold$target, y_pred)
  precision <- (cm[1,1] + cm[2,2]) / (cm[1,1] + cm[2,2] +cm[1,2] + cm[2,1])
  return(precision)
})

#Calculamos la media aritmética de k iteraciones
precisionNaiveBayes <- mean(as.numeric(cvNaiveBayes))
print(sprintf("La precisión para NaiveBayes en Cross Validation: %.4f %%",100*precisionNaiveBayes))
```

```{r}
vectorMedia = c(precisionC50ArbolClasificacion*100,precisionRegresionLogistica*100,precisionNaiveBayes*100)
vectorError = c(100-precisionC50ArbolClasificacion*100,100-precisionRegresionLogistica*100,100-precisionNaiveBayes*100)
vectorVarianza = c(var(as.numeric(cvC50ArbolClasificacion)*100), var(as.numeric(cvRegresionLogistica)*100), var(as.numeric(cvNaiveBayes)*100))
vectorDesviacion = c(sd(as.numeric(cvC50ArbolClasificacion)*100), sd(as.numeric(cvRegresionLogistica)*100), sd(as.numeric(cvNaiveBayes)*100))
M1 = cbind(c("Árbol Clasificacion", "Regresion Logistica","Naive Bayes"),vectorMedia,vectorError, vectorVarianza,vectorDesviacion)
colnames(M1) <- c("Modelo", "Porcentaje Predicción", "Error", "Varianza", "Desviación")
# Ordenamos y mostramos los resultados
M1[order(M1[,"Porcentaje Predicción"],decreasing = TRUE), ] 
```

Como podemos observar, ha aumentado levemente la precisión en la predicción al eliminar la variable slope, aunque la desviación estandar también aumento levemente, por lo que no podemos considerar relevante la eliminación de la variable en nuestros modelos predicctivos.


## Representación de los resultados a partir de tablas y gráficas. 

## Resolución del problema. A partir de los resultados obtenidos, ¿cuáles son las conclusiones? ¿Los resultados permiten responder al problema? 

Lo que se quería con este estudio era por una parte detectar características de los pacientes que infuyen en que se parezca la enfermedad cardíaca o no. Por otra parte poder predecir de una manera precisa si los individuos con unas características concretas sufren la enfermedad en un porcentaje alto.

El primer punto lo hemos conseguido responder con el análisis de los datos visuales y con la ayuda de algun análisis como la creación del árbol de clasificación que nos ha dado tambien una reglas. Por ejemplo, vemos que por diferenciando por sexo las mujeres tienen un más problemas cardíacos en porcentaje y que a menos oldpeak la probabilidad de sufrir la enfermedad es mayor. Las reglas obtenidas mediante el modelo C5.0 nos ha dado la información, como la siguiente:

-individus que cumplen trestbps <= 146 (presión arterial en reposo),oldpeak <= 0.7 (depresión del ST inducida por el ejercicio en relación con el descanso) y ca <= 0 (número de vasos principales coloreados por fluoroscopia) tienen problemas cardíacos en un 92 %


El segundo objetivo, el de obtener un modelo de predicción también ha sido conseguido. Se ha obtenido un modelo de regresión logística con más del 80% de precisión para predecir si una persona parece la enfermedad o no. 

Evidentemente, si se necesitara profundizar en algun aspecto se tendría que hacer una revisión para ajustar los modelos o buscar otros que se adecuen a las necesidades.

Para resolver las problemáticas hemos tenido que realizar las tareas habituales en un proyecto de datamining como son la limpieza y transformación de datos, la visualización y la generación de modelos.


## Código: Hay que adjuntar el código, preferiblemente en R, con el que se ha realizado la limpieza, análisis y representación de los datos. Si lo preferís, también podéis trabajar en Python.  

El código lo pueden encontrar en https://github.com/fmorenono/practica2

## Referencias

El Data Set seleccionado está disponible en :
https://www.kaggle.com/ronitf/heart-disease-uci


<br>
<br>

